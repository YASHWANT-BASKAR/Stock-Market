# -*- coding: utf-8 -*-
"""stock closing price prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KkroEyh1sVkyo5ANk3c8wdZtSGczfig3

# **Importing libraries and Data Pre-Processing**
"""

import pandas_datareader as pdr
import pandas as pd
import math
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense,LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

key = 'd2e845397925883df4bfe8b92d35e95dba9d24ca'
df = pdr.get_data_tiingo('HPQ', api_key = key) 
df.to_csv('AAPL.csv')
df = pd.read_csv('AAPL.csv')

df

df.shape

"""Visualizing the closing price history"""

plt.figure(figsize=(16,8))
plt.title('Close Price History')
plt.plot(df['close'])
plt.xlabel('Date',fontsize=18)
plt.ylabel('Close Price Usd ($)',fontsize=18)
plt.show()

#creating a new dataframe with only close dataframe
data=df.filter(['close'])
#converting the dataframe into a numpy array
dataset=data.values

#getting the number of rows to train the model 
training_data_len= math.ceil(len(dataset)* .8)
training_data_len

#scaling the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data= scaler.fit_transform(dataset)
scaled_data

#creating the training data set and scaling it
train_data = scaled_data[0:training_data_len , : ]
#splitting the data into x_train and y_train datasets
x_train=[]
y_train=[]
for i in range(60, len(train_data)):
  x_train.append(train_data[i-60:i,0])
  y_train.append(train_data[i,0])
  if i<=60:
    print(x_train)
    print(y_train)
    print()

#converting the x_train and y_train to a numpy array
x_train, y_train =np.array(x_train),np.array(y_train)

#reshaping the data
x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))
x_train.shape

"""# **Data Modelling**"""

model = Sequential()
model.add(LSTM(50,return_sequences = True,input_shape = (x_train.shape[1],1)))
model.add(LSTM(50,return_sequences = False))
model.add(Dense(25))
model.add(Dense(1))

model.compile(optimizer='adam',loss='mean_squared_error')

model.summary()

#training the model
history= model.fit(x_train, y_train, batch_size=64,epochs=100)

#creating the testing dataset
test_data= scaled_data[training_data_len-60: , :]
#creating the x_test and y_test datasets
x_test=[]
y_test= dataset[training_data_len:, :]
for i in range(60,len(test_data)):
  x_test.append(test_data[i-60:i,0])

#convert the data into a numpy array and reshaping it
x_test = np.array(x_test)
x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))

#get the models predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#RMSE
rmse= np.sqrt( np.mean ((( predictions-y_test)**2)))
rmse

"""# **Visualizing the data model**"""

#plotting the data
train= data[:training_data_len]
valid = data[training_data_len:]
valid['Predicted']=predictions
#visualizing the data
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date',fontsize=18)
plt.ylabel('Close Price USD($)',fontsize=18)
plt.plot(train['close'])
plt.plot(valid[['close','Predicted']])
plt.legend(['Train', 'Val','Predictions'],loc='lower right')
plt.show

# summarize history for loss
plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train'], loc='upper left')
plt.show()

#show the valid and predicted prices
valid

"""# **Predicting the next day's stock's closing price**"""

#predicting for the next day
new_df= df.filter(['close'])
last_60_days = new_df[-60:].values
last_60_days_scaled = scaler.transform(last_60_days)
X_test=[]
X_test.append(last_60_days_scaled)
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))
pred_price = model.predict(X_test)
pred_price = scaler.inverse_transform(pred_price)
pred_price

